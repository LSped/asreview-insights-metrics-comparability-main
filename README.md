
# Enhancing ASReview Insights with New Metric Focusing on Comparability
###



## Description
The goal of this project was to enhance the ASReview Insights Extension by adding the confusion matrix, which underlies most metrics, and by adding a new metric promoting comparability.

### New Features

Available in [ASReview Insights](https://github.com/asreview/asreview-insights)
- Confusion matrix components @recall 
- True Negative Rate @recall (TNR@r%) 

Not yet available in [ASReview Insights](https://github.com/asreview/asreview-insights)
- Confusion matrix @records screened
- Confusion matrix plots 
See scripts folder.


### Output

See output folder.

### Background


#### Confusion matrix

See [ASReview Insights](https://github.com/asreview/asreview-insights) for a definition of the confusion matrix in the active learning (AL) context.

#### Specificity / True Negative Rate (TNR) 

See [ASReview Insights](https://github.com/asreview/asreview-insights) for the definition and rationale of implementation.



## Table of contents

- `data` data access
- `scripts` modified scripts + explanations in readme
- `output` new metric JSON files, new cm plots 
- `Metrics-Implementation-Analysis` TNR & WSS analysis
- `gitignore`
- `LICENCE`
- `README.md`



## How to reproduce the project

### 1. Access data

See README in data folder.


### 2. Install software and packages

See README in scripts folder.

### 3. Run simulations

See README in scripts folder.

### 4. Jupyter Notebook

Open notebook, specifiy path to output/tables/data_metrics.csv, which is used for further analysis.


#### Contact 

[Email]


 


